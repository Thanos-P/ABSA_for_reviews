{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SP Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glove import *\n",
    "from myLayers import CustomAttention, Projection, MaskSum, WordAspectFusion\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.io.json._normalize import nested_to_record\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import metrics\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset and set data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv('../data/reviews_revision_train.csv', index_col=0)\n",
    "\n",
    "reviews['ids'] = reviews['ids'].apply(lambda x: list(map(int, x[1:-1].split(', '))))\n",
    "reviews['meta_review_pros'] = reviews['meta_review_pros'].apply(lambda x: x[2:-2].split('\\', \\''))\n",
    "reviews['meta_review_so-so'] = reviews['meta_review_so-so'].apply(lambda x: x[2:-2].split('\\', \\''))\n",
    "reviews['meta_review_cons'] = reviews['meta_review_cons'].apply(lambda x: x[2:-2].split('\\', \\''))\n",
    "reviews['meta_review_labels'] = reviews['meta_review_labels'].apply(lambda x: x[2:-2].split('\\', \\''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load GloVe model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 58990,
     "status": "ok",
     "timestamp": 1634105429613,
     "user": {
      "displayName": "Thanos Paraskevas",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "00658394908839401616"
     },
     "user_tz": -180
    },
    "id": "yxKirtl7TM8g"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'trained_models/el.glove.300.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8416/1788611303.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mglove_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGloveModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'trained_models/el.glove.300.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\Data\\e-Class\\Πτυχιακή\\Python\\FINAL\\glove.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[1;34m(cls, glove_file)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglove_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         \u001b[0memb_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprepare_embedding_retrieval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglove_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0memb_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Data\\e-Class\\Πτυχιακή\\Python\\FINAL\\glove.py\u001b[0m in \u001b[0;36mprepare_embedding_retrieval\u001b[1;34m(glove_file)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0membeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglove_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mitems\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'trained_models/el.glove.300.txt'"
     ]
    }
   ],
   "source": [
    "glove_model = GloveModel.from_pretrained('trained_models/el.glove.300.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reformat dataset rows to have a query aspect and a target aspect sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand the list of labels to separate rows and build a labels df\n",
    "labels = reviews['meta_review_labels'].apply(pd.Series).stack().rename('meta_review_labels').reset_index()\n",
    "\n",
    "# Join the labels df to the original df\n",
    "reviews = pd.merge(labels, reviews, left_on='level_0', right_index=True, suffixes=(['','_old']))[reviews.columns]\n",
    "\n",
    "# Rename column\n",
    "reviews = reviews.rename(columns={'meta_review_labels': 'aspect'})\n",
    "\n",
    "# Add product type as a prefix to aspect\n",
    "reviews['aspect_prefixed'] = reviews['meta_product_type'] + ' ' + reviews['aspect']\n",
    "\n",
    "# If aspect is 'Σχέση ποιότητας τιμής' make prefix 'Γενικά'\n",
    "reviews.loc[reviews['aspect'] == 'Σχέση ποιότητας τιμής', 'aspect_prefixed'] = 'Γενικά Σχέση ποιότητας τιμής'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read top labels (balanced labels with many instances) and drop the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/top_labels.txt', 'r', encoding='utf-8') as f:\n",
    "    f_lines = f.readlines()\n",
    "    top_labels = []\n",
    "    for i in f_lines:\n",
    "        top_labels.append(i.strip().replace('#', ' ').replace('_', ' '))\n",
    "        \n",
    "# Drop unbalanced aspects\n",
    "condition = False\n",
    "for label in top_labels:\n",
    "    condition |= (reviews['aspect_prefixed'] == label)\n",
    "condition = ~condition\n",
    "    \n",
    "reviews.drop(index=reviews[condition].index.tolist(), inplace=True)\n",
    "reviews.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get aspect ids using GloVe model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews['aspect_ids'] = reviews['aspect_prefixed'].apply(glove_model.string_to_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pad ids of each entry to match max length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_ids = keras.preprocessing.sequence.pad_sequences(\n",
    "    reviews['ids'].to_numpy(), padding=\"post\", value=0\n",
    ")\n",
    "\n",
    "padded_aspect_ids = keras.preprocessing.sequence.pad_sequences(\n",
    "    reviews['aspect_ids'].to_numpy(), padding=\"post\", maxlen=padded_ids.shape[-1], value=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform target labels to one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_category(df):\n",
    "    return [1 if df['aspect'] in df['meta_review_cons'] else 0,\n",
    "            1 if df['aspect'] in df['meta_review_so-so'] else 0,\n",
    "            1 if df['aspect'] in df['meta_review_pros'] else 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = np.array([elem for elem in reviews.apply(encode_category, axis='columns')])\n",
    "\n",
    "assert all(np.sum(target, axis=1) == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize embeddings layer with the weights of the GloVe model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_layer = keras.layers.Embedding(\n",
    "    input_dim=glove_model.emb_norm.shape[0], output_dim=glove_model.emb_norm.shape[1],\n",
    "    weights=[glove_model.emb_norm], name='embeddings', trainable=False,\n",
    "    mask_zero=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.layers.Input(shape=(padded_ids.shape[1],), dtype='int32', name='inputs')\n",
    "embeddings = embeddings_layer(inputs)\n",
    "\n",
    "hidden_embeddings = keras.layers.LSTM(128, return_sequences=True,\n",
    "    kernel_regularizer=keras.regularizers.l2(l=4e-6), name='lstm')(embeddings)\n",
    "\n",
    "hidden_embeddings = keras.layers.Dropout(0.5, name='dropout')(hidden_embeddings)\n",
    "\n",
    "aspect_input = keras.layers.Input(shape=(padded_aspect_ids.shape[1],),\n",
    "                                  dtype='int32', name='aspect_input')\n",
    "aspect_embedding = embeddings_layer(aspect_input)\n",
    "aspect_embedding_sum = MaskSum(name='aspect_sum')(aspect_embedding)\n",
    "\n",
    "word_aspect_fusion = WordAspectFusion(name='word_aspect_fusion')(\n",
    "    [hidden_embeddings, aspect_embedding_sum])\n",
    "\n",
    "after_attention = CustomAttention(name='attention')(\n",
    "    [hidden_embeddings, word_aspect_fusion])\n",
    "\n",
    "after_projection = Projection(name='projection')(\n",
    "    [after_attention, hidden_embeddings[:,-1,:]])\n",
    "\n",
    "after_projection = keras.layers.Dropout(0.5, name='dropout_1')(after_projection)\n",
    "\n",
    "outputs = keras.layers.Dense(3, activation='softmax', name='linear_softmax',\n",
    "                             kernel_regularizer=keras.regularizers.l2(l=4e-6))(\n",
    "    after_projection)\n",
    "\n",
    "model = keras.Model(inputs=[inputs, aspect_input], outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.CategoricalCrossentropy(),\n",
    "              optimizer=keras.optimizers.Adam(1e-3),\n",
    "              metrics=[keras.metrics.CategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras.utils.plot_model(model, show_shapes=True, dpi=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10, verbose=1,\n",
    "                                                  restore_best_weights=True)\n",
    "\n",
    "# Convert target one-hot labels to sparse labels\n",
    "target_sparse = np.argmax(target, axis=1)\n",
    "# and insert them to compute_class_weight() function\n",
    "class_weights = {i: w for i, w in enumerate(\n",
    "    class_weight.compute_class_weight('balanced',\n",
    "                                      classes=np.unique(target_sparse),\n",
    "                                      y=target_sparse)\n",
    ")}\n",
    "\n",
    "history = model.fit(\n",
    "    x=[padded_ids, padded_aspect_ids], y=target, epochs=50, batch_size=32,\n",
    "    callbacks=[early_stopping], class_weight=class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "myUtils.plot_graphs(history, 'categorical_accuracy')\n",
    "plt.ylim(None, 1)\n",
    "plt.subplot(1, 2, 2)\n",
    "myUtils.plot_graphs(history, 'loss')\n",
    "plt.ylim(0, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get attention layer from trained model and make it as an output to a new identical model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy layers of trained model\n",
    "hidden_embeddings = model.get_layer('lstm')\n",
    "aspect_fusion = model.get_layer('word_aspect_fusion')\n",
    "\n",
    "# create new attention layer that returns scores and connects to copied layers\n",
    "output = CustomAttention(return_scores=True, name='attention')(\n",
    "    [hidden_embeddings.output, aspect_fusion.output])\n",
    "\n",
    "# create new model with above layers\n",
    "atttention_model = keras.Model(inputs=[inputs, aspect_input], outputs=output)\n",
    "\n",
    "atttention_model.compile(loss=keras.losses.CategoricalCrossentropy(),\n",
    "                         optimizer=keras.optimizers.Adam(1e-3),\n",
    "                         metrics=['accuracy'])\n",
    "\n",
    "# set weights of attention layer of new model to be equal to trained one\n",
    "atttention_model.get_layer('attention').set_weights(model.get_layer('attention').get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('trained_models/SP_model_test.h5')\n",
    "atttention_model.save('trained_models/SP_attention_model_test.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
